{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reference.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngjaean/Python/blob/master/reference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fZZiSBwYk7UN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import stats\n",
        "from scipy.stats import norm, skew\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # warnings 무시\n",
        "%matplotlib inline\n",
        "\n",
        "# sns Theme \n",
        "sns.set_style('darkgrid') \n",
        "\n",
        "# 소수점 표현 제한\n",
        "pd.set_option('display.float_format', lambda x : '{:.3f}'.format(x))\n",
        "\n",
        "\n",
        "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
        "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor, RandomForestClassifier\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g8ypH-jwiSF_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "정규화 코드 "
      ]
    },
    {
      "metadata": {
        "id": "SMqYf90eiJ17",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# shape =train_df[\"SalePrice\"].shape\n",
        "#train_df['SalePrice'] = np.log1p(train_df['SalePrice'])\n",
        "# train_df[\"SalePrice\"]=np.random.uniform(low=np.sqrt(1.0/train_df[\"SalePrice\"]),\n",
        "#                                        high = np.sqrt(1.0/train_df[\"SalePrice\"]),size=shape)\n",
        "\n",
        "# train_df[\"SalePrice\"]=np.sqrt(2.0/train_df[\"SalePrice\"])*np.random.normal(size=shape)\n",
        "# 위에 세 코드는 정규화 코드 마지막 코드가 가장 최신 정규화 방법"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TAbjAQftYGPt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "null_data찾기 "
      ]
    },
    {
      "metadata": {
        "id": "remEXEXuYFYT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(all_data.isnull().sum()/len(all_data))*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cmTm-TDTkp4J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Roubust\n"
      ]
    },
    {
      "metadata": {
        "id": "Tho9vwxPkTqN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "robustScaler = RobustScaler()\n",
        "print(robustScaler.fit(train_data))\n",
        "train_data_robustScaled = robustScaler.transform(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b2hk_lIWmaHL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "그래프\n"
      ]
    },
    {
      "metadata": {
        "id": "3k-U12vakpR4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plt 그래프 두개를 한번에 출력\n",
        "#원형 그래프 \n",
        "f, ax = plt.subplots(1,2, figsize=(18,8))\n",
        "train_df['확인할 컬럼'].value_count().plot.pie(explode[0,0,1], autopct= '%1.1f%%',ax=ax[0],shadow=True)\n",
        "ax[0].set_title('제목')\n",
        "ax[0].set_ylabel('')\n",
        "#countplot\n",
        "sns.countplot(\"확인할 컬럼\",data=trian_df, ax=ax[1])\n",
        "ax[1].set_title(\"제목\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#heatmap\n",
        "\n",
        "heat =train_df.corr()\n",
        "\n",
        "colormap = plt.cm.RdBu\n",
        "plt.figure(figsize=(14, 12))\n",
        "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
        "sns.heatmap(heat_map.astype(float).corr(), linewidths=0.1, vmax=1.0,\n",
        "           square=True, cmap=colormap, linecolor='white', annot=True, annot_kws={\"size\": 3})\n",
        "\n",
        "del heat\n",
        "\n",
        "\n",
        "#정규 분포표 \n",
        "\n",
        "sns.distplot(train_df['컬럼'], fit=norm)\n",
        "plt.ylabel('이름')\n",
        "plt.title('제목')\n",
        "fig = plt.figure()\n",
        "res = stats.probplot(train_df['컬럼'], plot=plt)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#boxplot, vilolinplot\n",
        "\n",
        "fig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n",
        "\n",
        "sns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\n",
        "axis1.set_title('Pclass vs Fare Survival Comparison')\n",
        "\n",
        "sns.violinplot(x = 'Pclass', y = 'Age', hue = 'Survived', data = data1, split = True, ax = axis2)\n",
        "axis2.set_title('Pclass vs Age Survival Comparison')\n",
        "\n",
        "sns.boxplot(x = 'Pclass', y ='FamilySize', hue = 'Survived', data = data1, ax = axis3)\n",
        "axis3.set_title('Pclass vs Family Size Survival Comparison')\n",
        "\n",
        "#데이터 집합 그래프\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.scatter(x=train_df['GrLivArea'], y=train_df['SalePrice'])\n",
        "plt.ylabel('SalePrice', fontsize=13)\n",
        "plt.xlabel('GrLivArea', fontsize=13)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#다양한 그래프 한눈에 보기 \n",
        "g = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n",
        "       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\n",
        "g.set(xticklabels=[])\n",
        "\n",
        "#꺽은선 그래프\n",
        "grid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)\n",
        "grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\n",
        "grid.add_legend()\n",
        "\n",
        "#등고선 그래프 \n",
        "a = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\n",
        "a.map(sns.kdeplot, 'Age', shade= True )\n",
        "a.set(xlim=(0 , data1['Age'].max()))\n",
        "a.add_legend()\n",
        "\n",
        "\n",
        "#비교표 보기 \n",
        "train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3OOV2W1dkxdr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "모델 예시(분류, 회기)"
      ]
    },
    {
      "metadata": {
        "id": "IX8vruYZk1KN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# rando_forest\n",
        "random_forest=RandomForestRegressor(max_depth=20,max_features=\"sqrt\",min_samples_leaf=4, min_samples_split=10,\n",
        "                           n_estimators=1000)\n",
        "random_forest.fit(X_train, Y_train)\n",
        "random_forest_train_pred=random_forest.predict(X_train)\n",
        "random_forest_Y_pred = random_forest.predict(X_test)\n",
        "random_forest.score(X_train, Y_train)\n",
        "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
        "print(rmsle(Y_train, random_forest_train_pred))\n",
        "\n",
        "# GradienBoosting\n",
        "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4,\n",
        "                                   max_features='sqrt', min_samples_leaf=15, min_samples_split=10,\n",
        "                                   loss='huber', random_state=5)\n",
        "\n",
        "#lasso\n",
        "lasso = make_pipeline(RobustScaler(), Lasso(alpha=0.0005, random_state=1))\n",
        "\n",
        "#Enet\n",
        "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# GradienBoosting\n",
        "GradientBoostingClassifier(learning_rate=0.1, n_estimators=100,max_depth=3,\n",
        "                           min_samples_split=2, min_samples_leaf=1, \n",
        "                           subsample=1,max_features='sqrt', random_state=10)\n",
        "\n",
        "#SGD\n",
        "sgd = SGDClassifier()\n",
        "sgd.fit(X_train, Y_train)\n",
        "sgd_Y_pred = sgd.predict(X_test)\n",
        "print(rmsle(Y_train, sgd_Y_pred))\n",
        "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
        "print(acc_sgd)\n",
        "\n",
        "\n",
        "#KNN\n",
        "knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "knn.fit(X_train, Y_train)\n",
        "knn_Y_pred = knn.predict(X_test)\n",
        "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
        "acc_knn\n",
        "\n",
        "\n",
        "#SVM\n",
        "svc = SVC()\n",
        "svc.fit(X_train, Y_train)\n",
        "svc_Y_pred = svc.predict(X_test)\n",
        "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
        "acc_svc\n",
        "\n",
        "\n",
        "# rando_forest\n",
        "random_forest = RandomForestClassifier(n_estimators=100)\n",
        "random_forest.fit(X_train, Y_train)\n",
        "random_forest_train_pred=random_forest.predict(X_train)\n",
        "random_forest_Y_pred = random_forest.predict(X_test)\n",
        "random_forest.score(X_train, Y_train)\n",
        "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
        "print(rmsle(Y_train, random_forest_train_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_7HRs-LiUrT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "교차 검증 및  스태틱 모델\n"
      ]
    },
    {
      "metadata": {
        "id": "aRxEA43fiUNN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split, StratifiedKFold\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
        "    def __init__(self, base_models, meta_model, n_folds=5):\n",
        "        self.base_models = base_models\n",
        "        self.meta_model = meta_model\n",
        "        self.n_folds = n_folds\n",
        "   \n",
        "    # base_models_는 2차원 배열입니다.\n",
        "    def fit(self, X, y):\n",
        "        self.base_models_ = [list() for x in self.base_models]\n",
        "        self.meta_model_ = clone(self.meta_model)\n",
        "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
        "#         kfold = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
        "        \n",
        "        # Train cloned base models then create out-of-fold predictions\n",
        "        # that are needed to train the cloned meta-model\n",
        "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
        "        for i, model in enumerate(self.base_models):\n",
        "            for train_index, holdout_index in kfold.split(X, y):\n",
        "                instance = clone(model)\n",
        "                self.base_models_[i].append(instance)\n",
        "                instance.fit(X[train_index], y[train_index])\n",
        "                y_pred = instance.predict(X[holdout_index])\n",
        "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
        "                \n",
        "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
        "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
        "        return self\n",
        "   \n",
        "    # 각 모델들의 평균값을 사용합니다.\n",
        "    def predict(self, X):\n",
        "        meta_features = np.column_stack([\n",
        "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
        "            for base_models in self.base_models_ ])\n",
        "        return self.meta_model_.predict(meta_features)\n",
        "      \n",
        "def rmsle(y, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y, y_pred))\n",
        "  \n",
        "  \n",
        "n_folds = 5\n",
        "\n",
        "def rmsle_cv(model):\n",
        "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train_df.values)\n",
        "#     kfold = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
        "    rmse = np.sqrt(-cross_val_score(model, train_df.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
        "    return (rmse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K7NlAKRvkPu_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "스태틱 모델 예시"
      ]
    },
    {
      "metadata": {
        "id": "UYmeMK2ojZFM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stacked_averaged_models = StackingAveragedModels(\n",
        "    base_models=(ENet, GBoost, KRR,lasso),\n",
        "    meta_model=(RM)\n",
        ")\n",
        "\n",
        "score = rmsle_cv(stacked_averaged_models)\n",
        "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6RDb9wfFkhOZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "제출 파일 만들기"
      ]
    },
    {
      "metadata": {
        "id": "I98k0MA2kPiq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sub= pd.DataFrame()\n",
        "sub[\"Id\"] =test_ID\n",
        "sub[\"SalePrice\"]= stacked_pred\n",
        "sub.to_csv('submission.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}